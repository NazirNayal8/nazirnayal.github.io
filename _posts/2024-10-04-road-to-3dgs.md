---
layout: distill
title: Road to 3D Gaussian Splatting
description: A simplified and self-contained tutorial for understanding 3D Gaussian Splatting [Under Construction]
tags: ai tutorial 3d computer-vision
giscus_comments: true
date: 2024-10-04
featured: False
related_publications: true

authors:
  - name: Nazir Nayal
    url: "nazirnayal.xyz"
    affiliations:
      name: MPI-INF

bibliography: 2024-10-04-road-to-3dgs.bib

toc:
  - sidebar: left
 
---

## Introduction

  The end goal of this blog is to go over the necessary concepts and explanations to understand 3D Gaussian Splatting. I created this blog for my own learning and to simplify learning for others as well without the need to go around the internet gathering and intersecting the pieces of knowledge. This tutorial is based on several readings from different sources which will be cited with links.

## Problem Overview

  3D Gaussian Splatting is a deep learning-based method used to create an implicit 3D representation of a scene, which allows for projecting the scene on to a 2D surface from different view points.The 3D representation is learned from a view available images of the same scene from different view points, along with their camera position information. The goal is to make the representation general enough so that we can project the scene on to novel view points. Also, whatever representation we have, we need to have an algorithm to allow rendering for rendering to a 2D image.

---

## Representations of a 3D Scene

### Classical Representations

A 3D scene can be represented by one of the following:

1. **3D Mesh**: a set of vertices, edges, and faces that outline the 3D shape.
2. **Point Clouds**: a collection of points in 3D that represent an object. They can carry additional numerical information like color, density ...etc.
3. **Voxel Grids**: the 3D version of pixels. Essentially cubes that partition 3D space where each cube can carry additional information.

### Implicit Representations

  These include Neural Radiance Fields (NeRFs) and Gaussian Splatting, which will be discussed in detail in later sections.


---

## Neural Radiance Fields (NeRFs)


  In order to train a NeRF, we need to construct a dataset of $$N$$ images, each with its corresponding camera position information. Then, a neural network, (usually an MLP) is trained to take 5 coordinates $$(x, y, z, \theta, \phi)$$ as input, where $$(x, y, z)$$ are the 3D location information, and 
<!-- TODO: Validate the definition of theta and phi -->
  $$(\theta, \phi)$$ are the angles determining the view point angle. 
  The network outputs the color and density values for each pixel of an image of a particular view. The network hence can be optimized by matching the ground truth image with the generated one over the views available in the dataset <d-cite key="numbynum"></d-cite>.


### Volumetric Rendering
  

## 3D Gaussian Splatting


### Representation
  <!-- TODO: Expand on these at these with the proper reference -->
  <!-- TODO: Add explanation for quaternions as a dropdown menu or link -->
  <!-- TODO: Add explanation for Spherical Harmonics-->
  - Location ($$\mu$$): a tuple $$(x,y,z)$$ which also represents the "mean" of the Gaussian.
  - Covariance ($$\Sigma = RSS^TR^T$$): where $$S \in \mathbb{R}^{3 \times 3}$$ is diagonal scaling matrix showing the scale in 3D, and $$R \in \mathbb{R}^{3 \times 3}$$ is the rotation matrix. It can be expressed analytically using 4 **quaternions**. This factorization is known as the [eigendecomposition of a covariance matrix](https://www.visiondummy.com/2014/04/geometric-interpretation-covariance-matrix/#Covariance_matrix_as_a_linear_transformation). <d-cite key="overviewyurkova"></d-cite>
  - Opacity: a value between 0 and 1
  - Color parameters: either the RGB values or the coefficients of spherical harmonics.



<!-- Citations are then used in the article body with the `<d-cite>` tag.
The key attribute is a reference to the id provided in the bibliography.
The key attribute can take multiple ids, separated by commas.

The citation is presented inline like this: <d-cite key="numbynum"></d-cite> (a number that displays more information on hover).
If you have an appendix, a bibliography is automatically created and populated in it.
 -->

